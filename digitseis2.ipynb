{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richard/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 3\n",
    "epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = 20, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "train_0 = glob.glob('{}/scaled_training_images/{}/*'.format(current_dir, 'train_jpg_0'))\n",
    "train_1 = glob.glob('{}/scaled_training_images/{}/*'.format(current_dir, 'train_jpg_1'))\n",
    "train_2 = glob.glob('{}/scaled_training_images/{}/*'.format(current_dir, 'train_jpg_2'))\n",
    "\n",
    "def get_image_data(filename):\n",
    "    image = Image.open(filename)\n",
    "#     image = image.resize((img_x, img_y))\n",
    "    return np.array(image)\n",
    "\n",
    "def get_train_data(n):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for f in train_0[:n]:\n",
    "        train_data.append(get_image_data(f))\n",
    "        train_labels.append(0)\n",
    "    for f in train_1[:n]:\n",
    "        train_data.append(get_image_data(f))\n",
    "        train_labels.append(1)\n",
    "    for f in train_2[:n]:\n",
    "        train_data.append(get_image_data(f))\n",
    "        train_labels.append(2)\n",
    "    return np.asarray(train_data), np.asarray(train_labels)\n",
    "\n",
    "test = glob.glob('{}/scaled_training_images/{}/*'.format(current_dir, 'test_jpg'))\n",
    "def get_test_data(n):\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    for f in test[:n]:\n",
    "        test_data.append(get_image_data(f))\n",
    "        label = (f.split('/')[-1]).split('_')[0]\n",
    "        test_labels.append(int(label))\n",
    "    return np.asarray(test_data), np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = get_train_data(5000)\n",
    "x_test, y_test = get_test_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (15000, 20, 20, 1)\n",
      "15000 train samples\n",
      "1000 train samples\n",
      "Train on 15000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "15000/15000 [==============================] - 3s 209us/step - loss: 0.3958 - acc: 0.8385 - val_loss: 0.7189 - val_acc: 0.8300\n",
      "Epoch 2/50\n",
      "15000/15000 [==============================] - 3s 219us/step - loss: 0.2131 - acc: 0.9353 - val_loss: 0.5745 - val_acc: 0.8620\n",
      "Epoch 3/50\n",
      "15000/15000 [==============================] - 3s 200us/step - loss: 0.1710 - acc: 0.9487 - val_loss: 0.4347 - val_acc: 0.8800\n",
      "Epoch 4/50\n",
      "15000/15000 [==============================] - 3s 197us/step - loss: 0.1493 - acc: 0.9562 - val_loss: 0.6823 - val_acc: 0.8290\n",
      "Epoch 5/50\n",
      "15000/15000 [==============================] - 3s 208us/step - loss: 0.1352 - acc: 0.9605 - val_loss: 0.3356 - val_acc: 0.9080\n",
      "Epoch 6/50\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.1220 - acc: 0.9627 - val_loss: 0.3505 - val_acc: 0.9050\n",
      "Epoch 7/50\n",
      "15000/15000 [==============================] - 3s 209us/step - loss: 0.1120 - acc: 0.9671 - val_loss: 0.3424 - val_acc: 0.9020\n",
      "Epoch 8/50\n",
      "15000/15000 [==============================] - 3s 209us/step - loss: 0.1025 - acc: 0.9711 - val_loss: 0.3273 - val_acc: 0.9100\n",
      "Epoch 9/50\n",
      "15000/15000 [==============================] - 3s 217us/step - loss: 0.0980 - acc: 0.9716 - val_loss: 0.3989 - val_acc: 0.8930\n",
      "Epoch 10/50\n",
      "15000/15000 [==============================] - 3s 214us/step - loss: 0.0937 - acc: 0.9718 - val_loss: 0.3572 - val_acc: 0.9070\n",
      "Epoch 11/50\n",
      "15000/15000 [==============================] - 3s 220us/step - loss: 0.0864 - acc: 0.9749 - val_loss: 0.3630 - val_acc: 0.9090\n",
      "Epoch 12/50\n",
      "15000/15000 [==============================] - 3s 217us/step - loss: 0.0859 - acc: 0.9740 - val_loss: 0.4759 - val_acc: 0.8840\n",
      "Epoch 13/50\n",
      "15000/15000 [==============================] - 3s 216us/step - loss: 0.0841 - acc: 0.9750 - val_loss: 0.3864 - val_acc: 0.9050\n",
      "Epoch 14/50\n",
      "15000/15000 [==============================] - 3s 214us/step - loss: 0.0776 - acc: 0.9773 - val_loss: 0.4658 - val_acc: 0.9070\n",
      "Epoch 15/50\n",
      "15000/15000 [==============================] - 3s 220us/step - loss: 0.0754 - acc: 0.9764 - val_loss: 0.3465 - val_acc: 0.9120\n",
      "Epoch 16/50\n",
      "15000/15000 [==============================] - 3s 216us/step - loss: 0.0720 - acc: 0.9785 - val_loss: 0.4834 - val_acc: 0.8960\n",
      "Epoch 17/50\n",
      "15000/15000 [==============================] - 3s 219us/step - loss: 0.0693 - acc: 0.9787 - val_loss: 0.4469 - val_acc: 0.8970\n",
      "Epoch 18/50\n",
      "15000/15000 [==============================] - 3s 222us/step - loss: 0.0687 - acc: 0.9792 - val_loss: 0.3551 - val_acc: 0.9280\n",
      "Epoch 19/50\n",
      "15000/15000 [==============================] - 3s 220us/step - loss: 0.0624 - acc: 0.9813 - val_loss: 0.3973 - val_acc: 0.9200\n",
      "Epoch 20/50\n",
      "15000/15000 [==============================] - 3s 222us/step - loss: 0.0609 - acc: 0.9813 - val_loss: 0.4430 - val_acc: 0.8990\n",
      "Epoch 21/50\n",
      "15000/15000 [==============================] - 3s 216us/step - loss: 0.0559 - acc: 0.9838 - val_loss: 0.3682 - val_acc: 0.9260\n",
      "Epoch 22/50\n",
      "15000/15000 [==============================] - 3s 218us/step - loss: 0.0575 - acc: 0.9822 - val_loss: 0.4569 - val_acc: 0.9220\n",
      "Epoch 23/50\n",
      "15000/15000 [==============================] - 3s 213us/step - loss: 0.0584 - acc: 0.9827 - val_loss: 0.4021 - val_acc: 0.9210\n",
      "Epoch 24/50\n",
      "15000/15000 [==============================] - 3s 210us/step - loss: 0.0503 - acc: 0.9856 - val_loss: 0.4997 - val_acc: 0.9060\n",
      "Epoch 25/50\n",
      "15000/15000 [==============================] - 3s 207us/step - loss: 0.0469 - acc: 0.9859 - val_loss: 0.4529 - val_acc: 0.9070\n",
      "Epoch 26/50\n",
      "15000/15000 [==============================] - 3s 208us/step - loss: 0.0455 - acc: 0.9863 - val_loss: 0.5065 - val_acc: 0.9030\n",
      "Epoch 27/50\n",
      "15000/15000 [==============================] - 3s 207us/step - loss: 0.0511 - acc: 0.9851 - val_loss: 0.4705 - val_acc: 0.9210\n",
      "Epoch 28/50\n",
      "15000/15000 [==============================] - 3s 207us/step - loss: 0.0409 - acc: 0.9882 - val_loss: 0.5747 - val_acc: 0.9090\n",
      "Epoch 29/50\n",
      "15000/15000 [==============================] - 3s 208us/step - loss: 0.0412 - acc: 0.9882 - val_loss: 0.5058 - val_acc: 0.9160\n",
      "Epoch 30/50\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.0380 - acc: 0.9895 - val_loss: 0.4708 - val_acc: 0.9250\n",
      "Epoch 31/50\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.0456 - acc: 0.9866 - val_loss: 0.4908 - val_acc: 0.9140\n",
      "Epoch 32/50\n",
      "15000/15000 [==============================] - 3s 206us/step - loss: 0.0411 - acc: 0.9879 - val_loss: 0.5973 - val_acc: 0.9100\n",
      "Epoch 33/50\n",
      "15000/15000 [==============================] - 3s 204us/step - loss: 0.0394 - acc: 0.9889 - val_loss: 0.5932 - val_acc: 0.9110\n",
      "Epoch 34/50\n",
      "15000/15000 [==============================] - 3s 210us/step - loss: 0.0391 - acc: 0.9877 - val_loss: 0.5865 - val_acc: 0.9150\n",
      "Epoch 35/50\n",
      "15000/15000 [==============================] - 3s 208us/step - loss: 0.0421 - acc: 0.9879 - val_loss: 0.6518 - val_acc: 0.9000\n",
      "Epoch 36/50\n",
      "15000/15000 [==============================] - 3s 207us/step - loss: 0.0332 - acc: 0.9904 - val_loss: 0.5827 - val_acc: 0.9240\n",
      "Epoch 37/50\n",
      "15000/15000 [==============================] - 3s 204us/step - loss: 0.0457 - acc: 0.9862 - val_loss: 0.7301 - val_acc: 0.9050\n",
      "Epoch 38/50\n",
      "15000/15000 [==============================] - 3s 201us/step - loss: 0.0392 - acc: 0.9883 - val_loss: 0.5289 - val_acc: 0.9290\n",
      "Epoch 39/50\n",
      "15000/15000 [==============================] - 3s 204us/step - loss: 0.0294 - acc: 0.9919 - val_loss: 0.5795 - val_acc: 0.9120\n",
      "Epoch 40/50\n",
      "15000/15000 [==============================] - 3s 202us/step - loss: 0.0282 - acc: 0.9924 - val_loss: 0.6674 - val_acc: 0.8990\n",
      "Epoch 41/50\n",
      "15000/15000 [==============================] - 3s 214us/step - loss: 0.0360 - acc: 0.9900 - val_loss: 0.6872 - val_acc: 0.9110\n",
      "Epoch 42/50\n",
      "15000/15000 [==============================] - 3s 207us/step - loss: 0.0324 - acc: 0.9907 - val_loss: 0.6643 - val_acc: 0.9020\n",
      "Epoch 43/50\n",
      "15000/15000 [==============================] - 3s 205us/step - loss: 0.0306 - acc: 0.9911 - val_loss: 0.5934 - val_acc: 0.9090\n",
      "Epoch 44/50\n",
      "15000/15000 [==============================] - 3s 207us/step - loss: 0.0291 - acc: 0.9912 - val_loss: 0.6618 - val_acc: 0.9050\n",
      "Epoch 45/50\n",
      "15000/15000 [==============================] - 3s 211us/step - loss: 0.0228 - acc: 0.9935 - val_loss: 0.6419 - val_acc: 0.9110\n",
      "Epoch 46/50\n",
      "15000/15000 [==============================] - 3s 208us/step - loss: 0.0233 - acc: 0.9937 - val_loss: 0.7816 - val_acc: 0.9090\n",
      "Epoch 47/50\n",
      "15000/15000 [==============================] - 3s 207us/step - loss: 0.0411 - acc: 0.9875 - val_loss: 0.7413 - val_acc: 0.9050\n",
      "Epoch 48/50\n",
      "15000/15000 [==============================] - 3s 204us/step - loss: 0.0441 - acc: 0.9868 - val_loss: 0.5610 - val_acc: 0.9190\n",
      "Epoch 49/50\n",
      "15000/15000 [==============================] - 3s 209us/step - loss: 0.0251 - acc: 0.9930 - val_loss: 0.6648 - val_acc: 0.9060\n",
      "Epoch 50/50\n",
      "15000/15000 [==============================] - 4s 276us/step - loss: 0.0263 - acc: 0.9931 - val_loss: 0.8682 - val_acc: 0.8930\n",
      "Test loss: 0.8681951001286506\n",
      "Test accuracy: 0.893\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0Je5pJ9xbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13687f7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_cnn.py\n",
    "# reshape the data into a 4D tensor - (sample_number, x_img_size, y_img_size, num_channels)\n",
    "# because the MNIST is greyscale, we only have a single channel - RGB colour images would have 3\n",
    "x_train = x_train.reshape(x_train.shape[0], img_x, img_y, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_x, img_y, 1)\n",
    "input_shape = (img_x, img_y, 1)\n",
    "\n",
    "# convert the data to the right type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'train samples')\n",
    "\n",
    "# convert class vectors to binary class matrices - this is for use in the\n",
    "# categorical_crossentropy loss below\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history = AccuracyHistory()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[history])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "plt.plot(range(1, epochs+1), history.acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(folder):\n",
    "    train_0 = glob.glob('{}/training_images/{}/*'.format(current_dir, folder))\n",
    "    for f in train_0:\n",
    "        image = Image.open(f)\n",
    "        image = image.resize((img_x, img_y))\n",
    "        filename = f.split('/')[-1]\n",
    "        image.save('{}/scaled_training_images/{}/{}.jpg'.format(current_dir, folder, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2671dd355f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-987fbc463dcf>\u001b[0m in \u001b[0;36mtransform_data\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/training_images/{}/*'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/richard/anaconda/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2411\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# transform_data('test_jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
